{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KB-Bridge Demo\n",
    "\n",
    "KB-Bridge is an MCP server for intelligent knowledge base search with semantic search, query rewriting, and quality evaluation.\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. Install: `pip install kbbridge fastmcp`\n",
    "2. Configure: Create `.env` with backend credentials\n",
    "3. Start server: Run `ensure_server_running()` in the next cell\n",
    "4. Update `RESOURCE_ID` with your knowledge base ID\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "**Setup** (Cells 1-5)\n",
    "- Server management\n",
    "- MCP client setup\n",
    "\n",
    "**Quick Examples** (Cells 6-10)\n",
    "- ContractNLI examples\n",
    "\n",
    "**Core Tools** (Cells 11-35)\n",
    "- `assistant` - Q&A with answers\n",
    "- `file_discover` - Find relevant files\n",
    "- `file_lister` / `file_count` - List files\n",
    "- `keyword_generator` - Generate search keywords\n",
    "- `retriever` - Low-level search access\n",
    "\n",
    "**Advanced** (Cells 36-37)\n",
    "- Complete workflow with visualization\n",
    "- Error handling\n",
    "\n",
    "## Links\n",
    "\n",
    "- [GitHub](https://github.com/egpivo/kb-bridge) | [PyPI](https://pypi.org/project/kbbridge/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import server management utilities\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add examples directory to path\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'examples' / 'utils.py').exists():\n",
    "    sys.path.insert(0, str(cwd / 'examples'))\n",
    "elif (cwd.parent / 'examples' / 'utils.py').exists():\n",
    "    sys.path.insert(0, str(cwd.parent / 'examples'))\n",
    "\n",
    "try:\n",
    "    from utils import start_server, stop_server, show_logs, check_server_status, logs\n",
    "    \n",
    "    def ensure_server_running(port=5566):\n",
    "        \"\"\"Start server if not running\"\"\"\n",
    "        if not check_server_status():\n",
    "            start_server(port=port, kill_existing=True)\n",
    "        else:\n",
    "            print(\"Server already running\")\n",
    "    \n",
    "    print(\"‚úì Server utilities loaded\")\n",
    "    print(\"Use: start_server(port=5566) or ensure_server_running()\")\n",
    "except ImportError:\n",
    "    print(\"‚ö† Utils not available. Start server manually: python -m kbbridge.server --port 5566\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Management\n",
    "\n",
    "Start the server before running examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start server if not running\n",
    "ensure_server_running(port=5566)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MCP client and required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Add examples directory to path to import mcp_client\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'examples' / 'mcp_client.py').exists():\n",
    "    sys.path.insert(0, str(cwd / 'examples'))\n",
    "elif (cwd.parent / 'examples' / 'mcp_client.py').exists():\n",
    "    sys.path.insert(0, str(cwd.parent / 'examples'))\n",
    "\n",
    "try:\n",
    "    from mcp_client import ClientSession\n",
    "    print(\"‚úì MCP Client loaded\")\n",
    "except ImportError:\n",
    "    print(\"‚ö† mcp_client.py not found. Install httpx: pip install httpx\")\n",
    "    raise\n",
    "\n",
    "# Server configuration\n",
    "SERVER_URL = \"http://localhost:5566/mcp\"\n",
    "RESOURCE_ID = \"bfa61dd2-3514-4768-9014-e30eecdaf00f\"  # Replace with your actual resource ID\n",
    "\n",
    "print(f\"‚úì Server URL: {SERVER_URL}\")\n",
    "print(f\"‚úì Resource ID: {RESOURCE_ID} (update this with your actual resource ID)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Examples: ContractNLI\n",
    "\n",
    "Examples from the [ContractNLI dataset](https://stanfordnlp.github.io/contract-nli/).\n",
    "\n",
    "**Note**: Update `RESOURCE_ID` above with your knowledge base ID.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Non-Compete Clause\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def example_non_compete_clause():\n",
    "    \"\"\"Query about non-compete clause restrictions\"\"\"\n",
    "    query = \"Does the agreement include a non-compete clause restricting the employee from joining competitors?\"\n",
    "    \n",
    "    custom_instructions = \"\"\"\n",
    "    Extract: time periods (e.g., \"12 months\"), geographic scope (e.g., \"50-mile radius\"), \n",
    "    scope of restriction, and any exceptions. Cite exact text from the document.\n",
    "    \"\"\"\n",
    "    \n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        result = await session.call_tool(\"assistant\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"query\": query,\n",
    "            \"custom_instructions\": custom_instructions\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        \n",
    "        if \"answer\" in response_data:\n",
    "            print(\"Answer:\", response_data[\"answer\"])\n",
    "            if \"sources\" in response_data:\n",
    "                print(f\"\\nSources ({len(response_data['sources'])}):\")\n",
    "                for source in response_data[\"sources\"][:3]:\n",
    "                    print(f\"  - {source.get('title', 'Unknown')} (score: {source.get('score', 0):.3f})\")\n",
    "        else:\n",
    "            print(\"Error:\", response_data.get(\"error\", \"Unknown error\"))\n",
    "\n",
    "await example_non_compete_clause()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Termination Notice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def example_termination_notice():\n",
    "    \"\"\"Query about termination notice requirements with query rewriting\"\"\"\n",
    "    query = \"What is the notice period required for contract termination by either party?\"\n",
    "    \n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        # Query with rewriting enabled for better search results\n",
    "        result = await session.call_tool(\"assistant\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"query\": query,\n",
    "            \"enable_query_rewriting\": True,\n",
    "            \"custom_instructions\": \"Extract exact notice period (duration, method, effective date). Cite contract language.\"\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        \n",
    "        if \"answer\" in response_data:\n",
    "            print(\"Answer:\", response_data[\"answer\"])\n",
    "            if \"sources\" in response_data:\n",
    "                print(f\"\\nTop Sources:\")\n",
    "                for source in response_data[\"sources\"][:3]:\n",
    "                    print(f\"  - {source.get('title', 'Unknown')} (score: {source.get('score', 0):.3f})\")\n",
    "        else:\n",
    "            print(\"Error:\", response_data.get(\"error\", \"Unknown error\"))\n",
    "\n",
    "await example_termination_notice()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def basic_query_example():\n",
    "    \"\"\"Basic query example\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        result = await session.call_tool(\"assistant\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"query\": \"What are the safety protocols?\"\n",
    "        })\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        print(\"Answer:\", response_data.get(\"answer\", \"No answer found\"))\n",
    "        \n",
    "        # Display sources if available\n",
    "        if \"sources\" in response_data:\n",
    "            print(\"\\nSources:\")\n",
    "            for source in response_data[\"sources\"][:5]:  # Show first 5 sources\n",
    "                print(f\"  - {source.get('title', 'Unknown')} (score: {source.get('score', 0):.3f})\")\n",
    "\n",
    "# Run the example\n",
    "await basic_query_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Instructions\n",
    "\n",
    "Provide domain-specific guidance for answer extraction (useful for legal documents, contracts, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def custom_instructions_example():\n",
    "    \"\"\"Example with custom instructions\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        result = await session.call_tool(\"assistant\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"query\": \"What is the maternity leave policy?\",\n",
    "            \"custom_instructions\": \"Focus on HR compliance and legal requirements. Cite specific articles or sections.\"\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        print(\"Answer:\", response_data.get(\"answer\", \"No answer found\"))\n",
    "\n",
    "await custom_instructions_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Rewriting\n",
    "\n",
    "Enable LLM-based query expansion for better search results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query_rewriting_example():\n",
    "    \"\"\"Example with query rewriting enabled\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        result = await session.call_tool(\"assistant\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"query\": \"safety rules\",\n",
    "            \"enable_query_rewriting\": True  # Enables LLM-based query expansion/relaxation\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        print(\"Answer:\", response_data.get(\"answer\", \"No answer found\"))\n",
    "\n",
    "await query_rewriting_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document Filtering\n",
    "\n",
    "Limit search to a specific document using `document_name`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def document_filtering_example():\n",
    "    \"\"\"Example with document filtering\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        result = await session.call_tool(\"assistant\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"query\": \"What are the safety protocols?\",\n",
    "            \"document_name\": \"safety_manual.pdf\"  # Limit search to specific document\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        print(\"Answer:\", response_data.get(\"answer\", \"No answer found\"))\n",
    "\n",
    "await document_filtering_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. File Discovery\n",
    "\n",
    "Find relevant files before querying, then search specific files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def file_discovery_example():\n",
    "    \"\"\"Discover relevant files for a query\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        # Step 1: Discover relevant files\n",
    "        result = await session.call_tool(\"file_discover\", {\n",
    "            \"query\": \"employment policies\",\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"top_k_recall\": 100,  # Number of documents to retrieve\n",
    "            \"top_k_return\": 20,   # Number of files to return\n",
    "            \"do_file_rerank\": True,  # Enable reranking if available\n",
    "            \"relevance_score_threshold\": 0.0\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        \n",
    "        if response_data.get(\"success\"):\n",
    "            files = response_data.get(\"distinct_files\", [])\n",
    "            print(f\"Found {len(files)} relevant files:\")\n",
    "            for file in files[:10]:  # Show first 10 files\n",
    "                print(f\"  - {file}\")\n",
    "            \n",
    "            # Step 2: Query a specific file\n",
    "            if files:\n",
    "                print(f\"\\nQuerying specific file: {files[0]}\")\n",
    "                answer_result = await session.call_tool(\"assistant\", {\n",
    "                    \"resource_id\": RESOURCE_ID,\n",
    "                    \"query\": \"What are the vacation policies?\",\n",
    "                    \"document_name\": files[0]  # Use file from discovery\n",
    "                })\n",
    "                \n",
    "                answer_data = json.loads(answer_result.content[0].text)\n",
    "                print(\"Answer:\", answer_data.get(\"answer\", \"No answer found\"))\n",
    "        else:\n",
    "            print(\"File discovery failed:\", response_data.get(\"error\", \"Unknown error\"))\n",
    "\n",
    "await file_discovery_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. List Files\n",
    "\n",
    "List all files in your knowledge base (with pagination).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def file_lister_example():\n",
    "    \"\"\"List files in a knowledge base\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        result = await session.call_tool(\"file_lister\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"timeout\": 30,\n",
    "            \"limit\": 50,  # Limit number of files returned\n",
    "            \"offset\": 0   # Pagination offset\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        \n",
    "        if \"files\" in response_data:\n",
    "            files = response_data[\"files\"]\n",
    "            print(f\"Total files: {len(files)}\")\n",
    "            print(\"\\nFiles:\")\n",
    "            # Files are returned as a list of strings (file names)\n",
    "            for file_name in files[:20]:  # Show first 20 files\n",
    "                # Handle both string and dict formats for compatibility\n",
    "                if isinstance(file_name, str):\n",
    "                    print(f\"  - {file_name}\")\n",
    "                elif isinstance(file_name, dict):\n",
    "                    name = file_name.get(\"name\", \"Unknown\")\n",
    "                    size = file_name.get(\"size\", 0)\n",
    "                    print(f\"  - {name} ({size} bytes)\")\n",
    "                else:\n",
    "                    print(f\"  - {file_name}\")\n",
    "        else:\n",
    "            print(\"Error:\", response_data.get(\"error\", \"Unknown error\"))\n",
    "\n",
    "await file_lister_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. File Count\n",
    "\n",
    "Get the total number of files in your knowledge base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def file_count_example():\n",
    "    \"\"\"Get file count in knowledge base\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        result = await session.call_tool(\"file_count\", {\n",
    "            \"resource_id\": RESOURCE_ID\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        print(f\"File count: {response_data.get('file_count', 0)}\")\n",
    "        print(f\"Has files: {response_data.get('has_files', False)}\")\n",
    "\n",
    "await file_count_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Keyword Generation\n",
    "\n",
    "Generate search keywords using LLM to improve queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def keyword_generator_example():\n",
    "    \"\"\"Generate keywords for a query\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        result = await session.call_tool(\"keyword_generator\", {\n",
    "            \"query\": \"employee benefits and compensation\",\n",
    "            \"max_sets\": 5  # Number of keyword sets to generate\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        \n",
    "        if \"keyword_sets\" in response_data:\n",
    "            print(\"Generated keyword sets:\")\n",
    "            for i, keyword_set in enumerate(response_data[\"keyword_sets\"], 1):\n",
    "                print(f\"\\nSet {i}:\")\n",
    "                for keyword in keyword_set:\n",
    "                    print(f\"  - {keyword}\")\n",
    "        else:\n",
    "            print(\"Error:\", response_data.get(\"error\", \"Unknown error\"))\n",
    "\n",
    "await keyword_generator_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retriever Tool\n",
    "\n",
    "Low-level access to raw search results (no answer synthesis).\n",
    "\n",
    "**When to use:**\n",
    "- `assistant` ‚Üí Synthesized answers with citations\n",
    "- `retriever` ‚Üí Raw search chunks for custom processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retriever_example():\n",
    "    \"\"\"Use retriever tool for raw search results (no answer synthesis).\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        # Example: Hybrid search (semantic + keyword)\n",
    "        # Returns raw chunks: {\"result\": [{\"content\": \"...\", \"document_name\": \"...\"}]}\n",
    "        result = await session.call_tool(\"retriever\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"query\": \"What obligations remain in effect after the NDA expires, specifically regarding return or destruction of confidential information and survival of obligations for clinical trial data at University of Michigan?\",\n",
    "            \"search_method\": \"hybrid_search\",  # Options: \"hybrid_search\", \"semantic_search\", \"keyword_search\", \"full_text_search\", \"vector_search\"\n",
    "            \"does_rerank\": True,  # Enable reranking if available\n",
    "            \"top_k\": 10,  # Number of results to return\n",
    "            \"verbose\": False\n",
    "        })\n",
    "        \n",
    "        response_data = json.loads(result.content[0].text)\n",
    "        \n",
    "        # The retriever returns {\"result\": [{\"content\": \"...\", \"document_name\": \"...\"}]}\n",
    "        if \"result\" in response_data:\n",
    "            results = response_data[\"result\"]\n",
    "            print(f\"Retrieved {len(results)} results:\")\n",
    "            for i, item in enumerate(results[:5], 1):  # Show first 5\n",
    "                print(f\"\\nResult {i}:\")\n",
    "                document_name = item.get(\"document_name\", \"Unknown\")\n",
    "                content = item.get(\"content\", \"\")\n",
    "                print(f\"  Document: {document_name}\")\n",
    "                print(f\"  Content preview: {content[:200]}...\" if len(content) > 200 else f\"  Content: {content}\")\n",
    "        elif \"error\" in response_data:\n",
    "            print(f\"Error: {response_data['error']}\")\n",
    "            # Show format_error if available (from formatting issues)\n",
    "            if \"format_error\" in response_data:\n",
    "                print(f\"Format error: {response_data['format_error']}\")\n",
    "        else:\n",
    "            print(\"Error: Unknown error\")\n",
    "            print(f\"Response keys: {list(response_data.keys())}\")\n",
    "            print(f\"Response: {json.dumps(response_data, indent=2)[:500]}\")\n",
    "\n",
    "await retriever_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Complete Workflow\n",
    "\n",
    "End-to-end example: keyword generation ‚Üí file discovery ‚Üí answer extraction ‚Üí visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import FancyBboxPatch\n",
    "    MATPLOTLIB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MATPLOTLIB_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  matplotlib not available. Install with: pip install matplotlib\")\n",
    "    print(\"   Visualization will be skipped, but workflow will still run.\")\n",
    "\n",
    "\n",
    "def _is_valid_answer(answer_text):\n",
    "    \"\"\"Check if answer text is valid and meaningful.\"\"\"\n",
    "    if not answer_text or not answer_text.strip():\n",
    "        return False\n",
    "    upper_text = answer_text.strip().upper()\n",
    "    return upper_text not in ['N/A', 'N/A - NO RELEVANT INFORMATION FOUND', '']\n",
    "\n",
    "\n",
    "def _get_sources_count(answer_data):\n",
    "    \"\"\"Extract sources count from answer data, checking multiple locations.\"\"\"\n",
    "    # Try total_sources first\n",
    "    sources_count = answer_data.get('total_sources', 0)\n",
    "    if sources_count > 0:\n",
    "        return sources_count\n",
    "    \n",
    "    # Check reflection metadata\n",
    "    reflection = answer_data.get('reflection', {})\n",
    "    if isinstance(reflection, dict):\n",
    "        sources_count = reflection.get('sources_count', 0)\n",
    "        if sources_count > 0:\n",
    "            return sources_count\n",
    "        \n",
    "        # If quality_score exists, sources were evaluated\n",
    "        if reflection.get('quality_score', 0) > 0:\n",
    "            # Try structured_answer\n",
    "            structured_answer = answer_data.get('structured_answer', {})\n",
    "            if isinstance(structured_answer, dict):\n",
    "                structured_sources = structured_answer.get('sources', [])\n",
    "                if structured_sources:\n",
    "                    return len(structured_sources)\n",
    "            # At least one source was used if quality_score exists\n",
    "            return 1\n",
    "    \n",
    "    # If answer exists, at least one source was likely used\n",
    "    answer_text = answer_data.get('answer', '') or answer_data.get('text_summary', '')\n",
    "    if _is_valid_answer(answer_text):\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def _check_advanced_search_success(answer_data):\n",
    "    \"\"\"Determine if advanced search was successful.\"\"\"\n",
    "    total_sources = answer_data.get('total_sources', 0)\n",
    "    reflection = answer_data.get('reflection', {})\n",
    "    \n",
    "    if total_sources > 0:\n",
    "        return True\n",
    "    \n",
    "    if isinstance(reflection, dict):\n",
    "        # If quality_score exists, sources were evaluated\n",
    "        if reflection.get('quality_score', 0) > 0:\n",
    "            return True\n",
    "        # Check explicit sources_count\n",
    "        if reflection.get('sources_count', 0) > 0:\n",
    "            return True\n",
    "    \n",
    "    # If answer exists, at least one search method succeeded\n",
    "    answer_text = answer_data.get('answer', '') or answer_data.get('text_summary', '')\n",
    "    return _is_valid_answer(answer_text)\n",
    "\n",
    "\n",
    "def visualize_workflow_flow(answer_data, file_data=None, keyword_data=None):\n",
    "    \"\"\"\n",
    "    Visualize the KB-Bridge workflow as a flowchart showing information flow.\n",
    "    \n",
    "    Shows:\n",
    "    - Query input\n",
    "    - Keyword generation (if used)\n",
    "    - File discovery\n",
    "    - Direct search path\n",
    "    - Advanced search path\n",
    "    - Answer extraction\n",
    "    - Reflection/evaluation\n",
    "    - Final answer output\n",
    "    \n",
    "    Args:\n",
    "        answer_data: Response data from assistant tool\n",
    "        file_data: Optional file discovery results\n",
    "        keyword_data: Optional keyword generation results\n",
    "    \"\"\"\n",
    "    if not MATPLOTLIB_AVAILABLE:\n",
    "        raise ImportError(\"matplotlib is required for visualization\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Color scheme\n",
    "    colors = {\n",
    "        'query': '#4A90E2',\n",
    "        'process': '#7ED321',\n",
    "        'search': '#F5A623',\n",
    "        'success': '#50E3C2',\n",
    "        'fail': '#D0021B',\n",
    "        'output': '#9013FE'\n",
    "    }\n",
    "    \n",
    "    y_pos = 11\n",
    "    x_center = 5\n",
    "    \n",
    "    # Helper function to draw boxes\n",
    "    def draw_box(x, y, width, height, color, text, fontsize=10, bold=False):\n",
    "        box = FancyBboxPatch((x-width/2, y-height/2), width, height,\n",
    "                             boxstyle=\"round,pad=0.1\", facecolor=color,\n",
    "                             edgecolor='black', linewidth=1.5)\n",
    "        ax.add_patch(box)\n",
    "        weight = 'bold' if bold else 'normal'\n",
    "        ax.text(x, y, text, ha='center', va='center',\n",
    "                fontsize=fontsize, fontweight=weight, color='white' if color == colors['output'] else 'black')\n",
    "    \n",
    "    def draw_arrow(x, y, dx, dy, style='-'):\n",
    "        ax.arrow(x, y, dx, dy, head_width=0.15, head_length=0.08,\n",
    "                 fc='black', ec='black', linestyle=style)\n",
    "    \n",
    "    # 1. Query Input\n",
    "    draw_box(x_center, y_pos, 4, 0.8, colors['query'], 'User Query', fontsize=12, bold=True)\n",
    "    y_pos -= 1.5\n",
    "    draw_arrow(x_center, y_pos + 0.3, 0, -0.3)\n",
    "    y_pos -= 0.5\n",
    "    \n",
    "    # 2. Keyword Generation (if used)\n",
    "    if keyword_data and keyword_data.get('keyword_sets'):\n",
    "        kw_count = len(keyword_data.get('keyword_sets', []))\n",
    "        draw_box(x_center, y_pos, 4, 0.7, colors['process'],\n",
    "                f'Keyword Generation\\n({kw_count} sets)', fontsize=10, bold=True)\n",
    "        y_pos -= 1.2\n",
    "        draw_arrow(x_center, y_pos + 0.2, 0, -0.2)\n",
    "        y_pos -= 0.3\n",
    "    \n",
    "    # 3. File Discovery\n",
    "    if file_data:\n",
    "        file_count = len(file_data.get('distinct_files', []))\n",
    "        draw_box(x_center, y_pos, 4, 0.7, colors['process'],\n",
    "                f'File Discovery\\n({file_count} files found)', fontsize=10, bold=True)\n",
    "        y_pos -= 1.2\n",
    "        draw_arrow(x_center, y_pos + 0.2, 0, -0.2)\n",
    "        y_pos -= 0.3\n",
    "    \n",
    "    # 4. Search Approaches (Parallel)\n",
    "    y_search = y_pos - 0.5\n",
    "    \n",
    "    # Direct Search\n",
    "    answer_text = answer_data.get('answer', '') or answer_data.get('text_summary', '')\n",
    "    direct_success = _is_valid_answer(answer_text)\n",
    "    direct_color = colors['success'] if direct_success else colors['fail']\n",
    "    direct_status = \"[OK] Success\" if direct_success else \"[FAIL] No Results\"\n",
    "    draw_box(2.5, y_search, 3, 1, direct_color,\n",
    "            f'Direct Search\\n{direct_status}', fontsize=9, bold=True)\n",
    "    \n",
    "    # Advanced Search\n",
    "    has_advanced = _check_advanced_search_success(answer_data)\n",
    "    advanced_color = colors['success'] if has_advanced else colors['fail']\n",
    "    advanced_status = \"[OK] Success\" if has_advanced else \"[PARTIAL] Failed\"\n",
    "    draw_box(7.5, y_search, 3, 1, advanced_color,\n",
    "            f'Advanced Search\\n{advanced_status}', fontsize=9, bold=True)\n",
    "    \n",
    "    # Arrows from file discovery to both searches\n",
    "    draw_arrow(x_center, y_pos + 0.2, -1.5, -0.8, style='--')\n",
    "    draw_arrow(x_center, y_pos + 0.2, 1.5, -0.8, style='--')\n",
    "    \n",
    "    y_pos = y_search - 1.5\n",
    "    \n",
    "    # 5. Answer Extraction & Synthesis\n",
    "    sources_count = _get_sources_count(answer_data)\n",
    "    draw_box(x_center, y_pos, 5, 0.7, colors['search'],\n",
    "            f'Answer Extraction & Synthesis\\n({sources_count} sources)',\n",
    "            fontsize=10, bold=True)\n",
    "    y_pos -= 1.2\n",
    "    draw_arrow(x_center, y_pos + 0.2, 0, -0.2)\n",
    "    y_pos -= 0.3\n",
    "    \n",
    "    # 6. Reflection/Quality Evaluation (if enabled)\n",
    "    if 'reflection' in answer_data:\n",
    "        reflection = answer_data.get('reflection', {})\n",
    "        quality_score = reflection.get('quality_score', 0)\n",
    "        passed = reflection.get('passed', False)\n",
    "        ref_color = colors['success'] if passed else colors['fail']\n",
    "        status_text = \"[PASS]\" if passed else \"[FAIL]\"\n",
    "        draw_box(x_center, y_pos, 5, 0.7, ref_color,\n",
    "                f'{status_text} Reflection & Quality Check\\n(Score: {quality_score:.2f})',\n",
    "                fontsize=10, bold=True)\n",
    "        y_pos -= 1.2\n",
    "        draw_arrow(x_center, y_pos + 0.2, 0, -0.2)\n",
    "        y_pos -= 0.3\n",
    "    \n",
    "    # 7. Final Answer Output\n",
    "    if not answer_text or answer_text.strip().upper() in ['N/A', 'N/A - NO RELEVANT INFORMATION FOUND']:\n",
    "        answer_text = 'No answer found'\n",
    "    answer_preview = answer_text[:50] + \"...\" if len(answer_text) > 50 else answer_text\n",
    "    draw_box(x_center, y_pos, 5, 0.8, colors['output'],\n",
    "            f'Final Answer\\n\"{answer_preview}\"', fontsize=10, bold=True)\n",
    "    \n",
    "    # Title\n",
    "    ax.text(x_center, 11.8, 'KB-Bridge Information Flow',\n",
    "            ha='center', va='center', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def _display_reflection_analysis(reflection, answer):\n",
    "    \"\"\"Display detailed reflection analysis when quality is low.\"\"\"\n",
    "    quality_score = reflection.get(\"quality_score\")\n",
    "    threshold = reflection.get(\"threshold\", 0.7)\n",
    "    passed = reflection.get(\"passed\", True)\n",
    "    \n",
    "    # Determine analysis type\n",
    "    if answer == \"N/A - No relevant information found\":\n",
    "        title = \"üîç Reflection Analysis: Why No Results Were Found\"\n",
    "    else:\n",
    "        title = \"üîç Reflection Analysis: Why Quality Score is Low\"\n",
    "    \n",
    "    print(\"\\n\" + \"‚îÄ\" * 60)\n",
    "    print(title)\n",
    "    print(\"‚îÄ\" * 60)\n",
    "    \n",
    "    if quality_score is not None:\n",
    "        print(f\"\\nüìä Quality Assessment:\")\n",
    "        print(f\"   Quality Score: {quality_score:.2f} / {threshold:.2f}\")\n",
    "        print(f\"   Status: {'‚úÖ Passed' if passed else '‚ùå Below threshold'}\")\n",
    "        \n",
    "        # Show confidence level interpretation\n",
    "        confidence_level = reflection.get(\"confidence_level\", \"\")\n",
    "        if confidence_level:\n",
    "            confidence_map = {\n",
    "                \"high\": \"‚úÖ High confidence - answer is reliable\",\n",
    "                \"medium\": \"‚ö†Ô∏è  Medium confidence - answer may need verification\",\n",
    "                \"low\": \"‚ö†Ô∏è  Low confidence - answer quality is below acceptable threshold\",\n",
    "                \"very_low\": \"‚ùå Very low confidence - answer is likely incorrect or incomplete\"\n",
    "            }\n",
    "            print(f\"   Confidence: {confidence_map.get(confidence_level, confidence_level)}\")\n",
    "    \n",
    "    # Show detailed feedback\n",
    "    feedback = reflection.get(\"feedback\", \"\")\n",
    "    if feedback:\n",
    "        print(f\"\\nüí° Reflection Feedback:\")\n",
    "        print(f\"   {feedback}\")\n",
    "    \n",
    "    # Show detailed scores breakdown\n",
    "    scores = reflection.get(\"scores\", {})\n",
    "    if scores:\n",
    "        print(f\"\\nüìà Detailed Quality Scores:\")\n",
    "        for metric, score in scores.items():\n",
    "            print(f\"   {metric.capitalize()}: {score:.2f}\")\n",
    "    \n",
    "    # Show recommendations if available\n",
    "    recommendation = reflection.get(\"recommendation\", \"\")\n",
    "    if recommendation:\n",
    "        print(f\"\\nüí° Recommendation:\")\n",
    "        print(f\"   {recommendation}\")\n",
    "    \n",
    "    # Show re-extraction suggestion if available\n",
    "    if reflection.get(\"re_extraction_recommended\"):\n",
    "        candidates_count = reflection.get(\"re_extraction_candidates\", 0)\n",
    "        print(f\"\\nüîÑ Re-extraction Opportunity:\")\n",
    "        print(f\"   {candidates_count} candidates have segments but extraction failed.\")\n",
    "        print(f\"   Re-extraction with improved parameters may help.\")\n",
    "\n",
    "\n",
    "async def complete_workflow_example(reflection_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Complete workflow: keyword generation ‚Üí file discovery ‚Üí answer extraction ‚Üí visualization.\n",
    "    \n",
    "    Args:\n",
    "        reflection_threshold: Quality threshold (0-1). Default 0.5. Lower = more lenient.\n",
    "    \"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        query = \"What obligations remain in effect after the NDA expires, specifically regarding return or destruction of confidential information and survival of obligations for clinical trial data at University of Michigan?\"\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"üîÑ Complete Workflow Example\")\n",
    "        print(f\"   Reflection Threshold: {reflection_threshold}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Generate keywords\n",
    "        print(\"\\n1Ô∏è‚É£ Generating keywords...\")\n",
    "        keyword_result = await session.call_tool(\"keyword_generator\", {\n",
    "            \"query\": query,\n",
    "            \"max_sets\": 3\n",
    "        })\n",
    "        keyword_data = json.loads(keyword_result.content[0].text)\n",
    "        if \"keyword_sets\" in keyword_data:\n",
    "            print(f\"   ‚úÖ Generated {len(keyword_data['keyword_sets'])} keyword sets\")\n",
    "        \n",
    "        # Step 2: Discover relevant files\n",
    "        print(\"\\n2Ô∏è‚É£ Discovering relevant files...\")\n",
    "        file_result = await session.call_tool(\"file_discover\", {\n",
    "            \"query\": query,\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"top_k_return\": 10\n",
    "        })\n",
    "        file_data = json.loads(file_result.content[0].text)\n",
    "        files = file_data.get(\"distinct_files\", [])\n",
    "        print(f\"   ‚úÖ Found {len(files)} relevant files\")\n",
    "        \n",
    "        # Step 3: Query assistant with reflection enabled\n",
    "        print(\"\\n3Ô∏è‚É£ Querying assistant (with reflection and verbose mode)...\")\n",
    "        answer_result = await session.call_tool(\"assistant\", {\n",
    "            \"resource_id\": RESOURCE_ID,\n",
    "            \"query\": query,\n",
    "            \"custom_instructions\": \"Provide a comprehensive answer with specific details. Cite sources.\",\n",
    "            \"enable_query_rewriting\": True,\n",
    "            \"enable_reflection\": True,\n",
    "            \"reflection_threshold\": reflection_threshold,\n",
    "            \"verbose\": True\n",
    "        })\n",
    "        answer_data = json.loads(answer_result.content[0].text)\n",
    "        \n",
    "        # Display final answer\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üì§ Final Answer\")\n",
    "        print(\"=\" * 60)\n",
    "        answer = answer_data.get(\"answer\", answer_data.get(\"text_summary\", \"No answer found\"))\n",
    "        print(answer)\n",
    "        \n",
    "        # Show reflection insights when quality is low or answer indicates no results\n",
    "        if \"reflection\" in answer_data:\n",
    "            reflection = answer_data.get(\"reflection\", {})\n",
    "            quality_score = reflection.get(\"quality_score\")\n",
    "            passed = reflection.get(\"passed\", True)\n",
    "            \n",
    "            # Show analysis if quality is low or answer indicates no results\n",
    "            # Use reflection_threshold instead of hardcoded 0.7\n",
    "            threshold = reflection.get(\"threshold\", reflection_threshold)\n",
    "            if not passed or (quality_score is not None and quality_score < threshold) or answer == \"N/A - No relevant information found\":\n",
    "                _display_reflection_analysis(reflection, answer)\n",
    "        \n",
    "        # Show sources if available\n",
    "        if \"sources\" in answer_data and answer_data[\"sources\"]:\n",
    "            print(f\"\\nüìö Sources ({len(answer_data['sources'])}):\")\n",
    "            for source in answer_data[\"sources\"][:5]:\n",
    "                print(f\"   ‚Ä¢ {source.get('title', 'Unknown')}\")\n",
    "        \n",
    "        # Visualize the workflow flow\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìä Workflow Visualization\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\nGenerating information flow diagram...\")\n",
    "        print(\"\\nüí° Note: Advanced search may show as 'Failed' even when direct search succeeds.\")\n",
    "        print(\"   This happens because:\")\n",
    "        print(\"   - Advanced search processes files individually with per-file top_k limits\")\n",
    "        print(\"   - Segments might rank differently within files vs. across all files\")\n",
    "        print(\"   - Direct search aggregates results across all files (more forgiving)\")\n",
    "        print(\"   - KB-Bridge automatically uses the best results from either approach\")\n",
    "        \n",
    "        # Generate visualization if matplotlib is available\n",
    "        if MATPLOTLIB_AVAILABLE:\n",
    "            try:\n",
    "                fig = visualize_workflow_flow(answer_data, file_data, keyword_data)\n",
    "                plt.show()\n",
    "                print(\"\\n‚úÖ Workflow diagram displayed above\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ö†Ô∏è  Could not generate visualization: {e}\")\n",
    "                print(\"   (This is optional - the workflow still completed successfully)\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  Visualization skipped (matplotlib not installed)\")\n",
    "            print(\"   Install with: pip install matplotlib\")\n",
    "            print(\"\\nüìã Text Summary of Workflow:\")\n",
    "            print(\"   1. User Query ‚Üí Keyword Generation ‚Üí File Discovery\")\n",
    "            print(\"   2. Parallel Search: Direct Search + Advanced Search\")\n",
    "            print(\"   3. Answer Extraction & Synthesis\")\n",
    "            if 'reflection' in answer_data:\n",
    "                print(\"   4. Reflection & Quality Check\")\n",
    "            print(\"   5. Final Answer Output\")\n",
    "\n",
    "# Run with lower threshold (0.5) so scores like 0.51 will pass and show green\n",
    "await complete_workflow_example()\n",
    "\n",
    "# To use stricter threshold, uncomment:\n",
    "# await complete_workflow_example(reflection_threshold=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Error Handling\n",
    "\n",
    "Handle errors gracefully when working with the API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def error_handling_example():\n",
    "    \"\"\"Example of error handling\"\"\"\n",
    "    async with ClientSession(SERVER_URL) as session:\n",
    "        try:\n",
    "            result = await session.call_tool(\"assistant\", {\n",
    "                \"resource_id\": \"invalid-resource-id\",\n",
    "                \"query\": \"test query\"\n",
    "            })\n",
    "            \n",
    "            response_data = json.loads(result.content[0].text)\n",
    "            \n",
    "            if \"error\" in response_data:\n",
    "                print(f\"Error occurred: {response_data['error']}\")\n",
    "                print(f\"Message: {response_data.get('message', 'No message')}\")\n",
    "            else:\n",
    "                print(\"Success:\", response_data.get(\"answer\", \"No answer\"))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred: {type(e).__name__}: {e}\")\n",
    "\n",
    "await error_handling_example()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
